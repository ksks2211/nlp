{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "train_data = pd.read_csv(DATA_IN_PATH+'train.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  ...                                          question2 is_duplicate\n",
       "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
       "1   1     3  ...  What would happen if the Indian government sto...            0\n",
       "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
       "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
       "4   4     9  ...            Which fish would survive in salt water?            0\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_data = train_data.loc[train_data['is_duplicate']==1]\n",
    "train_neg_data = train_data.loc[train_data['is_duplicate']==0]\n",
    "\n",
    "\n",
    "# 개수의 차이\n",
    "class_difference = len(train_neg_data) - len(train_pos_data)\n",
    "# 많은 집단에서는 일부만 샘플링하기\n",
    "sample_frac = 1 - (class_difference / len(train_neg_data))\n",
    "train_neg_data = train_neg_data.sample(frac = sample_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 질문 개수: 149263\n",
      "중복이 아닌 질문 개수: 149263\n"
     ]
    }
   ],
   "source": [
    "print(\"중복 질문 개수: {}\".format(len(train_pos_data)))\n",
    "print(\"중복이 아닌 질문 개수: {}\".format(len(train_neg_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 다시 합치기\n",
    "train_data = pd.concat([train_neg_data, train_pos_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "MAX_SEQUENCE_LENGTH = 31\n",
    "\n",
    "change_filter = re.compile(FILTERS)\n",
    "questions1 = [str(s) for s in train_data['question1']]\n",
    "questions2 = [str(s) for s in train_data['question2']]\n",
    "filtered_questions1 = list()\n",
    "filtered_questions2 = list()\n",
    "\n",
    "for q in questions1:\n",
    "     filtered_questions1.append(re.sub(change_filter, \"\", q).lower())\n",
    "        \n",
    "for q in questions2:\n",
    "     filtered_questions2.append(re.sub(change_filter, \"\", q).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(filtered_questions1 + filtered_questions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "questions1_sequence = tokenizer.texts_to_sequences(filtered_questions1)\n",
    "questions2_sequence = tokenizer.texts_to_sequences(filtered_questions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[30, 5, 267, 160, 1084, 28, 163, 884, 3266, 20, 311, 31, 64],\n",
       " [4, 3, 114, 75, 259, 244, 308, 34, 1, 6451, 1934]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions1_sequence[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "MAX_SEQUENCE_LENGTH = 31\n",
    "q1_data = pad_sequences(questions1_sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "q2_data = pad_sequences(questions2_sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question1 data: (298526, 31)\n",
      "Shape of question2 data:(298526, 31)\n",
      "Shape of label: (298526,)\n",
      "Words in index: 76595\n"
     ]
    }
   ],
   "source": [
    "word_vocab = {}\n",
    "word_vocab = tokenizer.word_index \n",
    "word_vocab[\"<PAD>\"] = 0\n",
    "\n",
    "labels = np.array(train_data['is_duplicate'], dtype=int)\n",
    "\n",
    "print('Shape of question1 data: {}'.format(q1_data.shape))\n",
    "print('Shape of question2 data:{}'.format(q2_data.shape))\n",
    "print('Shape of label: {}'.format(labels.shape))\n",
    "print(\"Words in index: {}\".format(len(word_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  30,    5,  267,  160, 1084,   28,  163,  884, 3266,   20,  311,\n",
       "          31,   64,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   4,    3,  114,   75,  259,  244,  308,   34,    1, 6451, 1934,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_configs = {}\n",
    "data_configs['vocab'] = word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_Q1_DATA = 'train_q1.npy'\n",
    "TRAIN_Q2_DATA = 'train_q2.npy'\n",
    "TRAIN_LABEL_DATA = 'train_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "np.save(open(DATA_IN_PATH + TRAIN_Q1_DATA, 'wb'), q1_data)\n",
    "np.save(open(DATA_IN_PATH + TRAIN_Q2_DATA , 'wb'), q2_data)\n",
    "np.save(open(DATA_IN_PATH + TRAIN_LABEL_DATA , 'wb'), labels)\n",
    "\n",
    "json.dump(data_configs, open(DATA_IN_PATH + DATA_CONFIGS, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(DATA_IN_PATH + 'test.csv', encoding='utf-8')\n",
    "# test_data = test_data.drop(test_data.tail(1217679).index,inplace=True) # drop last n rows\n",
    "valid_ids = [type(x) ==int for x in test_data.test_id] \n",
    "test_data = test_data[valid_ids].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions1 = [str(s) for s in test_data['question1']]\n",
    "test_questions2 = [str(s) for s in test_data['question2']]\n",
    "\n",
    "filtered_test_questions1 = list()\n",
    "filtered_test_questions2 = list()\n",
    "\n",
    "for q in test_questions1:\n",
    "     filtered_test_questions1.append(re.sub(change_filter, \"\", q).lower())\n",
    "        \n",
    "for q in test_questions2:\n",
    "     filtered_test_questions2.append(re.sub(change_filter, \"\", q).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "test_questions1_sequence = tokenizer.texts_to_sequences(filtered_test_questions1)\n",
    "test_questions2_sequence = tokenizer.texts_to_sequences(filtered_test_questions2)\n",
    "\n",
    "# add padding\n",
    "test_q1_data = pad_sequences(test_questions1_sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "test_q2_data = pad_sequences(test_questions2_sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question1 data: (2345796, 31)\n",
      "Shape of question2 data:(2345796, 31)\n",
      "Shape of ids: (2345796,)\n"
     ]
    }
   ],
   "source": [
    "# 평가데이터의 아이디\n",
    "\n",
    "test_id = np.array(test_data['test_id'])\n",
    "\n",
    "print('Shape of question1 data: {}'.format(test_q1_data.shape))\n",
    "print('Shape of question2 data:{}'.format(test_q2_data.shape))\n",
    "print('Shape of ids: {}'.format(test_id.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_Q1_DATA = 'test_q1.npy'\n",
    "TEST_Q2_DATA = 'test_q2.npy'\n",
    "TEST_ID_DATA = 'test_id.npy'\n",
    "\n",
    "np.save(open(DATA_IN_PATH + TEST_Q1_DATA, 'wb'), test_q1_data)\n",
    "np.save(open(DATA_IN_PATH + TEST_Q2_DATA , 'wb'), test_q2_data)\n",
    "np.save(open(DATA_IN_PATH + TEST_ID_DATA , 'wb'), test_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
